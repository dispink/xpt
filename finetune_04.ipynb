{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the finetuned model\n",
    "The intention was to check if our new codes (systematically modified into command line base) are able to reproduce the performance from the old codes. However, since we decided to deal with one kind of measurement for each model in the new codes, there is no straightforward way to compare the two versions of codes. And the old model didn't provide excellent performance either. I then changed to the target, \"if the new codes generate ok performance\". Later on, we will conduct a series of hyperparameter tuning to improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.eval.eval import finetune_evaluate, finetune_evaluate_base\n",
    "from src.models.mae_vit_regressor import mae_vit_base_patch16\n",
    "from src.datas import transforms\n",
    "from src.datas.dataloader import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaCO3\n",
      "MSE: 0.202\n",
      "MSE of base model: 98.973\n",
      "R2: 0.998\n"
     ]
    }
   ],
   "source": [
    "# CaCO3\n",
    "target = \"CaCO3\"\n",
    "criterion = torch.nn.MSELoss()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "target_mean = torch.load(f\"src/datas/xpt_{target}_target_mean.pth\")\n",
    "target_std = torch.load(f\"src/datas/xpt_{target}_target_std.pth\")\n",
    "target_transform = transforms.Normalize(target_mean, target_std)\n",
    "\n",
    "model = mae_vit_base_patch16(pretrained=True, weights=f\"results/finetune_test_{target}_20240610/model.ckpt\").to(device)\n",
    "dataloader = get_dataloader(ispretrain=False, annotations_file=f\"data/finetune/{target}%/train/info.csv\", input_dir=f\"data/finetune/{target}%/train\", \n",
    "                            batch_size=256, transform=transforms.InstanceNorm(), target_transform=target_transform, num_workers=8)\n",
    "\n",
    "model_mse = finetune_evaluate(model=model, dataloader=dataloader['val'], criterion=criterion)\n",
    "\n",
    "base_mse = finetune_evaluate_base(dataloader=dataloader['val'], criterion=criterion, mean=target_mean)\n",
    "\n",
    "r_square = 1 - model_mse / base_mse\n",
    "\n",
    "print(target)\n",
    "print(f'MSE: {model_mse:.3f}')\n",
    "print(f'MSE of base model: {base_mse:.3f}')\n",
    "print(f'R2: {r_square:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC\n",
      "MSE: 0.244\n",
      "MSE of base model: 1.076\n",
      "R2: 0.773\n"
     ]
    }
   ],
   "source": [
    "# TOC\n",
    "target = \"TOC\"\n",
    "criterion = torch.nn.MSELoss()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "target_mean = torch.load(f\"src/datas/xpt_{target}_target_mean.pth\")\n",
    "target_std = torch.load(f\"src/datas/xpt_{target}_target_std.pth\")\n",
    "target_transform = transforms.Normalize(target_mean, target_std)\n",
    "\n",
    "model = mae_vit_base_patch16(pretrained=True, weights=f\"results/finetune_test_{target}_20240610/model.ckpt\").to(device)\n",
    "dataloader = get_dataloader(ispretrain=False, annotations_file=f\"data/finetune/{target}%/train/info.csv\", input_dir=f\"data/finetune/{target}%/train\", \n",
    "                            batch_size=256, transform=transforms.InstanceNorm(), target_transform=target_transform, num_workers=8)\n",
    "\n",
    "model_mse = finetune_evaluate(model=model, dataloader=dataloader['val'], criterion=criterion)\n",
    "\n",
    "base_mse = finetune_evaluate_base(dataloader=dataloader['val'], criterion=criterion, mean=target_mean)\n",
    "\n",
    "r_square = 1 - model_mse / base_mse\n",
    "\n",
    "print(target)\n",
    "print(f'MSE: {model_mse:.3f}')\n",
    "print(f'MSE of base model: {base_mse:.3f}')\n",
    "print(f'R2: {r_square:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "The models not just give ok performance. They have relevat or even slightly better performance than the results in Lee et al. (2022). The CaCO3 model's R2 is 0.998 which outperforms 0.96 in Lee et al. (2022). The TOC model's R2 is 0.773 which is relevant to 0.78 in Lee et al. (2022). Okay, let's move on to the hyperparameter tuning after some minor modifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
