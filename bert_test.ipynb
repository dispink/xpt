{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Know about BERT a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "# when you load from pretrained\n",
    "model = transformers.BertForMaskedLM.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask = transformers.pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.10833366960287094, 'token': 9529, 'token_str': 'Frankfurt', 'sequence': 'It is known that Frankfurt is the capital of Germany'}\n",
      "{'score': 0.0837741494178772, 'token': 11212, 'token_str': 'Leipzig', 'sequence': 'It is known that Leipzig is the capital of Germany'}\n",
      "{'score': 0.06412549316883087, 'token': 1122, 'token_str': 'it', 'sequence': 'It is known that it is the capital of Germany'}\n",
      "{'score': 0.055242475122213364, 'token': 3206, 'token_str': 'Berlin', 'sequence': 'It is known that Berlin is the capital of Germany'}\n",
      "{'score': 0.05167430639266968, 'token': 8339, 'token_str': 'Hamburg', 'sequence': 'It is known that Hamburg is the capital of Germany'}\n"
     ]
    }
   ],
   "source": [
    "# perform predictions with only one mask\n",
    "example = \"It is known that [MASK] is the capital of Germany\"\n",
    "for prediction in fill_mask(example):\n",
    "  print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.11870907247066498, 'token': 9529, 'token_str': 'Frankfurt', 'sequence': '[CLS] It is known that Frankfurt is [MASK] capital of Germany [SEP]'}, {'score': 0.09645532071590424, 'token': 11212, 'token_str': 'Leipzig', 'sequence': '[CLS] It is known that Leipzig is [MASK] capital of Germany [SEP]'}, {'score': 0.07038077712059021, 'token': 17339, 'token_str': 'Bremen', 'sequence': '[CLS] It is known that Bremen is [MASK] capital of Germany [SEP]'}, {'score': 0.05996522679924965, 'token': 8339, 'token_str': 'Hamburg', 'sequence': '[CLS] It is known that Hamburg is [MASK] capital of Germany [SEP]'}, {'score': 0.053893789649009705, 'token': 3206, 'token_str': 'Berlin', 'sequence': '[CLS] It is known that Berlin is [MASK] capital of Germany [SEP]'}]\n",
      "[{'score': 0.9693134427070618, 'token': 1103, 'token_str': 'the', 'sequence': '[CLS] It is known that [MASK] is the capital of Germany [SEP]'}, {'score': 0.008970746770501137, 'token': 170, 'token_str': 'a', 'sequence': '[CLS] It is known that [MASK] is a capital of Germany [SEP]'}, {'score': 0.004885075148195028, 'token': 1208, 'token_str': 'now', 'sequence': '[CLS] It is known that [MASK] is now capital of Germany [SEP]'}, {'score': 0.0016494009178131819, 'token': 1393, 'token_str': 'former', 'sequence': '[CLS] It is known that [MASK] is former capital of Germany [SEP]'}, {'score': 0.0009498320869170129, 'token': 1954, 'token_str': 'current', 'sequence': '[CLS] It is known that [MASK] is current capital of Germany [SEP]'}]\n"
     ]
    }
   ],
   "source": [
    "# perform predictions with two masks\n",
    "example = \"It is known that [MASK] is [MASK] capital of Germany\"\n",
    "for prediction in fill_mask(example):\n",
    "  print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.11870907247066498, 'token': 9529, 'token_str': 'Frankfurt', 'sequence': '[CLS] It is known that Frankfurt is [MASK] capital of Germany [SEP]'}\n",
      "{'score': 0.09645532071590424, 'token': 11212, 'token_str': 'Leipzig', 'sequence': '[CLS] It is known that Leipzig is [MASK] capital of Germany [SEP]'}\n",
      "{'score': 0.07038077712059021, 'token': 17339, 'token_str': 'Bremen', 'sequence': '[CLS] It is known that Bremen is [MASK] capital of Germany [SEP]'}\n",
      "{'score': 0.05996522679924965, 'token': 8339, 'token_str': 'Hamburg', 'sequence': '[CLS] It is known that Hamburg is [MASK] capital of Germany [SEP]'}\n",
      "{'score': 0.053893789649009705, 'token': 3206, 'token_str': 'Berlin', 'sequence': '[CLS] It is known that Berlin is [MASK] capital of Germany [SEP]'}\n",
      "==================================================\n",
      "{'score': 0.9693134427070618, 'token': 1103, 'token_str': 'the', 'sequence': '[CLS] It is known that [MASK] is the capital of Germany [SEP]'}\n",
      "{'score': 0.008970746770501137, 'token': 170, 'token_str': 'a', 'sequence': '[CLS] It is known that [MASK] is a capital of Germany [SEP]'}\n",
      "{'score': 0.004885075148195028, 'token': 1208, 'token_str': 'now', 'sequence': '[CLS] It is known that [MASK] is now capital of Germany [SEP]'}\n",
      "{'score': 0.0016494009178131819, 'token': 1393, 'token_str': 'former', 'sequence': '[CLS] It is known that [MASK] is former capital of Germany [SEP]'}\n",
      "{'score': 0.0009498320869170129, 'token': 1954, 'token_str': 'current', 'sequence': '[CLS] It is known that [MASK] is current capital of Germany [SEP]'}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for prediction in fill_mask(example):\n",
    "    for pre in prediction:\n",
    "        print(pre)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that BERT only predicts one mask at a time...But not many details are given under this wrapped pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step by step\n",
    "Let's examine more details. I go through it based on the [YT tutorial](https://www.youtube.com/watch?v=q9NS5WpfkrU&t=1s). It's following videos could be helpful as well.\n",
    "\n",
    "Perhaps [BERT 101](https://huggingface.co/blog/bert-101) from HG is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   139,  9637,  1942,   117,  1603,  1111,   139,  2386,  5817,\n",
       "         17264, 13832, 13775,  1197, 20777,  4894, 20936,  1116,  1121, 25267,\n",
       "           117,  1110,   170,  7792,  9681,   113,   150,  2162,   114,  2235,\n",
       "          1111,  2379,  1846,  6165,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = \"BERT, short for Bidirectional Encoder Representations from Transformers, is a Machine Learning (ML) model for natural language processing.\"\n",
    "inputs = tokenizer(example, return_tensors=\"pt\")\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "tensor([[  101,   139,  9637,  1942,   117,  1603,  1111,   139,  2386,  5817,\n",
      "         17264, 13832, 13775,  1197, 20777,  4894, 20936,  1116,  1121, 25267,\n",
      "           117,  1110,   170,  7792,  9681,   113,   150,  2162,   114,  2235,\n",
      "          1111,  2379,  1846,  6165,   119,   102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.keys())\n",
    "print(inputs[\"input_ids\"])\n",
    "print(inputs[\"token_type_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   139,  9637,  1942,   117,  1603,  1111,   139,  2386,  5817,\n",
      "         17264, 13832, 13775,  1197, 20777,  4894, 20936,  1116,  1121, 25267,\n",
      "           117,  1110,   170,  7792,  9681,   113,   150,  2162,   114,  2235,\n",
      "          1111,  2379,  1846,  6165,   119,   102]])\n"
     ]
    }
   ],
   "source": [
    "inputs['labels'] = inputs['input_ids'].clone()\n",
    "print(inputs['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3833, 0.4233, 0.6101, 0.8474, 0.4840, 0.1935, 0.3732, 0.0623, 0.6702,\n",
      "         0.5749, 0.4297, 0.1022, 0.3344, 0.0406, 0.2400, 0.6945, 0.1701, 0.1315,\n",
      "         0.1819, 0.0654, 0.5040, 0.2206, 0.6792, 0.5919, 0.5604, 0.7918, 0.0377,\n",
      "         0.9316, 0.7125, 0.7666, 0.9865, 0.4611, 0.7818, 0.9955, 0.2688, 0.1095]])\n",
      "torch.Size([1, 36])\n"
     ]
    }
   ],
   "source": [
    "rand = torch.rand(inputs['labels'].shape)\n",
    "print(rand)\n",
    "print(rand.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False,  True, False, False,\n",
       "         False,  True, False,  True, False, False, False,  True, False,  True,\n",
       "         False, False, False, False, False, False,  True, False, False, False,\n",
       "         False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15% of tokens that are not the special tokens ([CLS], [END]) are masked\n",
    "mask_arr = (rand < 0.15) * (inputs['input_ids'] != 101) * (inputs['input_ids'] != 102)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7], [11], [13], [17], [19], [26]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tokens are sublists of the list so it needs to be flattened\n",
    "mask_arr[0].nonzero().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 11, 13, 17, 19, 26]\n"
     ]
    }
   ],
   "source": [
    "slection = torch.flatten(mask_arr[0].nonzero()).tolist()\n",
    "print(slection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,   139,  9637,  1942,   117,  1603,  1111,   103,  2386,  5817,\n",
       "         17264,   103, 13775,   103, 20777,  4894, 20936,   103,  1121,   103,\n",
       "           117,  1110,   170,  7792,  9681,   113,   103,  2162,   114,  2235,\n",
       "          1111,  2379,  1846,  6165,   119,   102]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply masks (token 103) to the inputs\n",
    "inputs.input_ids[0, slection] = 103\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits'])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : torch.Size([])\n",
      "logits : torch.Size([1, 36, 28996])\n"
     ]
    }
   ],
   "source": [
    "for key, value in outputs.items():\n",
    "    print(key, \":\", value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  119,   139,  9637,  1942,   117,  1603,  1111,   139,  2386,  5817,\n",
       "        17264, 13832, 13775,  6828, 20777,  4894, 20936,   117,  1121,  1483,\n",
       "          117,  1110,   170,  7792,  9681,   113,   150,  2162,   114,  2235,\n",
       "         1111,  2379,  1846,  6165,   119,   119])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits[0, :, :].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". BERT, short for Bidirectional Encode Language Representation, from English, is a Machine Learning ( ML ) model for natural language processing..\n"
     ]
    }
   ],
   "source": [
    "# transform the predicted token ids to token strings\n",
    "predicted_text = tokenizer.decode(\n",
    "    token_ids=outputs.logits[0, :, :].argmax(dim=-1)\n",
    "    )\n",
    "print(predicted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model actually calculates the logits of all input tokens. Each of the 36 tokens has 28996 logits (the vocab size) implying the probability of each token's predicted label. This matches the mechanism of self-attention, i.e. the model see all the inputs. Therefore, the confussion I had about how BERT predicts the masked tokens is solved. It simply predicts everything.\n",
    "\n",
    "According to [the original paper](https://arxiv.org/abs/1810.04805), the model only cares about the masked token's logits in terms of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted masked token ids:\n",
      "139\n",
      "13832\n",
      "20936\n",
      "6828\n",
      "2379\n",
      "119\n",
      "==================================================\n",
      "Actual masked token ids:\n",
      "139\n",
      "13832\n",
      "20936\n",
      "25267\n",
      "2379\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted masked token ids:\")\n",
    "for predictions in outputs.logits[0, slection, :]:\n",
    "    print(predictions.argmax().item())\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"Actual masked token ids:\")\n",
    "for label in inputs['labels'][0, slection]:\n",
    "    print(label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masked accuracy is 5/6. Not bad!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
